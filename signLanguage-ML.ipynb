{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "signLanguage-ML",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpKHh-cVhDVr",
        "colab_type": "text"
      },
      "source": [
        "*Sign Language - Machine Learning*\n",
        "\n",
        "---\n",
        "\n",
        "Seminarski rad u sklopu kursa Mašinsko učenje - Matematički fakultet, Univerzitet u Beogradu\n",
        "\n",
        "**Autori**  \n",
        "Nikola Dimić i Zorana Gajić"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js3s3xGNh1yA",
        "colab_type": "text"
      },
      "source": [
        "**Opis projekta**  \n",
        " Cilj ovog projekta jeste da se konstruiše model za klasifikaciju slika znakovnog jezika kako bismo olakšali njegovo učenje i razumevanje.\n",
        "\n",
        "**Baza podataka**  \n",
        "Baza podataka sadrži 3000 slika za svako slovo. Znakovi su slikani iz različitih uglova i pod različitim osvetljenjem, kako bi se dobio što precizniji model. Link do baze je [ovde](https://www.kaggle.com/paultimothymooney/interpret-sign-language-with-deep-learning/data).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHB-Uc_g7rb0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7121065a-97fa-494c-80ad-bfd03b67c0d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vDl7rhO7_kO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b2292b9-5341-4407-abf5-3d3050873a5f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omEX0XVW8akk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip drive/My\\ Drive/input.zip -d data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbFXsceqj_fy",
        "colab_type": "text"
      },
      "source": [
        "**Neophodne biblioteke**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkHECs2HhCJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import optimizers\n",
        "from keras import utils\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqqxzbXXFQdw",
        "colab_type": "text"
      },
      "source": [
        "**Pretprocesiranje slika**\n",
        "\n",
        "Slike znakovnog jezika nalaze se u datotekama razvrstane po slovima. Prilikom učitavanja svake od datoteka, slika je obrađena u skladu sa potrebama mreže koja se trenira. Tako je svaka slika smanjena ili povećana u skladu sa odgovarajućim dimenzijama. Svakoj slici dodeljena je klasa u skladu sa datotekom u kojoj se nalaze, s tim što su klase konvertovane iz slovnog u brojevni zapis pa tako su slova *A,B...Z* redom označena rednim brojevima slova u abecedi (*0,1..25*), dok su specijalni karakteri *del*, *nothing* i *space* označeni brojevima *26,27,28* respektivno. Nakon obrade slika i pridruživanja klasa, ispisane su specifikacije skupa podataka, kao i dimenzije matrica kojima su opisane slike. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5pniroKf12g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def letterToNumber(letter):\n",
        "    if(len(letter) == 1):\n",
        "        letterNum = ord(letter.lower()) - 97\n",
        "    elif(letter == 'del'):\n",
        "        letterNum = 26\n",
        "    elif(letter == 'nothing'):\n",
        "        letterNum = 27\n",
        "    elif(letter == 'space'):\n",
        "        letterNum = 28\n",
        "    else:\n",
        "        letterNum = 29\n",
        "    return letterNum\n",
        "\n",
        "def proccessImage(imageFile, size=(200,200), color = True):\n",
        "    color = 3 if color else 1\n",
        "    resizedImage = resize(imageFile, (size[0], size[1], color), anti_aliasing=True)\n",
        "    return np.asarray(resizedImage)\n",
        "\n",
        "def resizeData(X, size=(200,200), color = True):\n",
        "    Xnew = map(lambda img: proccessImage(img,size,color), X)\n",
        "    return list(Xnew)\n",
        "\n",
        "def logData(imageColor, imageSize, imagesPerLetter, item):\n",
        "    print(\"Extracted data with the following specifications:\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "    print(\"color: \" + str(imageColor))\n",
        "    print(\"size: \" + str(imageSize))\n",
        "    print(\"images per letter: \" + str(imagesPerLetter))\n",
        "    print(\"output shape: \" + str(item.shape))\n",
        "\n",
        "def exctractDataFromFiles(file, imageColor = True, imageSize = (200,200), imagesPerLetter='all'):\n",
        "    color = 1 if imageColor else 0\n",
        "    X = []\n",
        "    y = []\n",
        "    for folderName in os.listdir(file):\n",
        "        if not folderName.startswith('.'):\n",
        "            classLetter = folderName\n",
        "            classNum = letterToNumber(classLetter)\n",
        "            fullFolderName = file+folderName\n",
        "            listOfImages = os.listdir(fullFolderName)\n",
        "            random.shuffle(listOfImages)\n",
        "            numOfImages = len(listOfImages) if imagesPerLetter == 'all' else imagesPerLetter\n",
        "            \n",
        "            for imageName in tqdm(listOfImages[0:numOfImages]):\n",
        "                fullImageName = fullFolderName + \"/\" + imageName\n",
        "                imageFile = cv2.imread(fullImageName, color)\n",
        "                resizedImage = proccessImage(imageFile, imageSize, color)   \n",
        "                X.append(resizedImage)\n",
        "                y.append(classNum)\n",
        "    X = np.asarray(X)\n",
        "    y = np.asarray(y)\n",
        "    logData(imageColor, imageSize, imagesPerLetter, X[0])\n",
        "    return X,y\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w80zMr6-9voM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64c22ccf-1223-440a-aafb-b7f038079ca7"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDZMpXAif4Sc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "c06760c8-b795-404d-d429-18b2c9ed1736"
      },
      "source": [
        "trainFolder = \"./data/input/asl-alphabet/asl_alphabet_train/\"\n",
        "#testFolder =  \"../input/asl-alphabet/asl_alphabet_test/\"\n",
        "\n",
        "X, y = exctractDataFromFiles(trainFolder, imageColor = True, imageSize = (50, 50), imagesPerLetter = 1000)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:07<00:00, 128.53it/s]\n",
            "100%|██████████| 1000/1000 [00:07<00:00, 130.89it/s]\n",
            "100%|██████████| 1000/1000 [00:07<00:00, 132.03it/s]\n",
            "100%|██████████| 1000/1000 [00:07<00:00, 132.95it/s]\n",
            "100%|██████████| 1000/1000 [00:07<00:00, 136.28it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 85.86it/s]\n",
            "100%|██████████| 1000/1000 [00:12<00:00, 82.06it/s]\n",
            "100%|██████████| 1000/1000 [00:12<00:00, 82.09it/s]\n",
            "100%|██████████| 1000/1000 [00:12<00:00, 81.41it/s]\n",
            "100%|██████████| 1000/1000 [00:12<00:00, 82.84it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 84.53it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 86.28it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 86.21it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 86.53it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 85.87it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 87.61it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 88.65it/s]\n",
            "100%|██████████| 1000/1000 [00:10<00:00, 91.81it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 89.50it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 89.61it/s]\n",
            "100%|██████████| 1000/1000 [00:10<00:00, 91.12it/s]\n",
            "100%|██████████| 1000/1000 [00:10<00:00, 91.68it/s]\n",
            "100%|██████████| 1000/1000 [00:10<00:00, 91.67it/s]\n",
            "100%|██████████| 1000/1000 [00:10<00:00, 91.14it/s]\n",
            "100%|██████████| 1000/1000 [00:11<00:00, 89.99it/s]\n",
            "100%|██████████| 1000/1000 [00:10<00:00, 94.69it/s]\n",
            "100%|██████████| 1000/1000 [00:10<00:00, 93.50it/s]\n",
            "100%|██████████| 1000/1000 [00:10<00:00, 95.99it/s]\n",
            "100%|██████████| 1000/1000 [00:10<00:00, 95.43it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracted data with the following specifications:\n",
            "--------------------------------------------------\n",
            "color: True\n",
            "size: (50, 50)\n",
            "images per letter: 1000\n",
            "output shape: (50, 50, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avppEdDznuaU",
        "colab_type": "text"
      },
      "source": [
        "**Prikaz slike**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMXfEmE5nwOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testImage = cv2.imread(\"../input/asl-alphabet/asl_alphabet_train/A/A1.jpg\")\n",
        "resizedTestImage = proccessImage(testImage, size=(50,50), color=True)\n",
        "print(resizedTestImage.shape)\n",
        "plt.imshow(resizedTestImage, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3UlCC_1oOqQ",
        "colab_type": "text"
      },
      "source": [
        "**Pretprocesiranje ciljne promenljive**  \n",
        "U sklopu transformacije ciljne promenljive je korišćeno `One-Hot encoding`, odnosno kodiranje koje kategoričkom atributu (ciljnoj promenljivoj) sa $k$ mogućih različitih vrednosti (gde je $k$ u našem slučaju vrednost 30) pridružuje $k$ novih promenljivih, a vrednostima kategoričke promenljive vrednosti indikatora.\n",
        "\n",
        "0 &#8594; 1 0 0 0 ... 0  \n",
        "1 &#8594; 0 1 0 0 ... 0  \n",
        "2 &#8594; 0 0 1 0 ... 0  \n",
        "...  \n",
        "29 &#8594; 0 0 0 0 ... 0  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-wuT8Jcnz3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numOfClasses = 30"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld49YQSBJ-4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One hot encoding of target variable\n",
        "y = to_categorical(y, numOfClasses)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whyh6YvElG1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKs1M7gfo1as",
        "colab_type": "text"
      },
      "source": [
        "**Podela podataka na trening i test skup**  \n",
        "Učitani podaci se dele na trening i test skup u odnosu *3:1*, s tim što se uz pomoć naglašenog parametra *stratify* čuva udeo ciljne promenljive iz originalnog skupa podataka."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhdRcPBjo5MC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0alb6Y_o7w2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7f3a1477-4169-48c8-dbd0-20cc694ca3db"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19430, 50, 50, 3)\n",
            "(9570, 50, 50, 3)\n",
            "(19430, 30)\n",
            "(9570, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh8I5lzkH8RN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbb9e2a5-81c6-45d0-f029-307e9e121fba"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-cuuaa3IG65",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b583ad86-d2e2-4510-cddd-387a68363eeb"
      },
      "source": [
        "np.save(\"./data/Xtrain\", X_train)\n",
        "np.save(\"./data/Xtest\", X_test)\n",
        "print(\"X saved\")\n",
        "np.save(\"./data/Ytrain\", y_train)\n",
        "np.save(\"./data/Ytest\", y_test)\n",
        "print(\"Y saved\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X saved\n",
            "Y saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNi4U5wpJt7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "864f9fe3-440c-4467-be29-cb76b8a46096"
      },
      "source": [
        "X_train = np.load(\"./data/Xtrain.npy\")\n",
        "X_test = np.load(\"./data/Xtest.npy\")\n",
        "print(\"X loaded\")\n",
        "y_train = np.load(\"./data/Ytrain.npy\")\n",
        "y_test = np.load(\"./data/Ytest.npy\")\n",
        "print(\"Y loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X loaded\n",
            "Y loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySST93ix8EeR",
        "colab_type": "text"
      },
      "source": [
        "**Početni model**  \n",
        "Prvi pokušaj rešavanja problema je bila konvolutivna neuronska mreža sa arhitekturom sličnoj onoj prikazanoj na vežbama. Naime, korišćena je neuronska mreža sa propagacijom unapred, gde se dodaju sledeći slojevi:  \n",
        "**1 sloj:** Konvolucioni sloj sa *16* filtera, kernelom veličine *3x3*, uokvirenjem tako da veličina izlazne slike može biti istih dimenzija i *ReLu* aktivacionom funkcijom.    \n",
        "**2 sloj:** Agregacioni sloj koji vrši redukciju slojeva svođenjem blokova zadatih večina na njihove maksimalne vrednosti i veličinom bloka *2x2*.  \n",
        "**3 sloj:** Konvolucioni sloj sa *32* filtera, kernelom veličine *3x3*, uokvirenjem tako da veličina izlazne slike može biti istih dimenzija i *ReLu* aktivacionom funkcijom.    \n",
        "**4 sloj:** Agregacioni sloj koji vrši redukciju slojeva svođenjem blokova zadatih večina na njihove maksimalne vrednosti i veličinom bloka *2x2*.  \n",
        "**5 sloj:** Konvolucioni sloj sa *64* filtera, kernelom veličine *3x3*, uokvirenjem tako da veličina izlazne slike može biti istih dimenzija i *ReLu* aktivacionom funkcijom.  \n",
        "Zatim funkcija koja se koristi za transformisanje matrica u vektore *Flatten*.    \n",
        "**6 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *1024* i ReLu aktivacionom funkcijom.  \n",
        "Zatim tehnika regularizacije kojom isključujemo nasumično odabrane neurone i omogućavamo drugačiji protok podataka kroz mrežu *Dropout*.\n",
        "**7 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *30* i *softmax* aktivacionom funkcijom. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MABi2BPLVlEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aumCLaL1pjPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOBAR MODEL ZA COLOR \n",
        "# Training model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(50,50,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(numOfClasses, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_vFQths36sb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "faf0c927-a156-472b-aac4-eed1a7f8df6e"
      },
      "source": [
        "# Model summary per layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_35 (Conv2D)           (None, 50, 50, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 25, 25, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 12, 12, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1024)              2360320   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 30)                30750     \n",
            "=================================================================\n",
            "Total params: 2,414,654\n",
            "Trainable params: 2,414,654\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOCSGl504gF_",
        "colab_type": "text"
      },
      "source": [
        "**Mrežu ćemo trenirati prema sledećim smernicama:**  \n",
        "*Funkcija greške*: Kategorička unakrsna entropija  \n",
        "*Optimizator*: Adam sa korakom učenja **0.001**   \n",
        "*Broj epoha*: **12**  \n",
        "*Veličina paketića za treniranje* (engl. batch size): **128**  \n",
        "\n",
        "Za evaluaciju mreže koristimo **preciznost**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLH-PSLY37Lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci9R2-o537aD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bae276c8-dcb4-46cc-aa9e-6bb26df317e3"
      },
      "source": [
        "# Train model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2, \n",
        "                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "122/122 [==============================] - 1s 10ms/step - loss: 2.6705 - accuracy: 0.2304 - val_loss: 1.6855 - val_accuracy: 0.5023\n",
            "Epoch 2/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 1.3445 - accuracy: 0.5731 - val_loss: 0.8719 - val_accuracy: 0.7337\n",
            "Epoch 3/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.7832 - accuracy: 0.7441 - val_loss: 0.5147 - val_accuracy: 0.8482\n",
            "Epoch 4/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.4999 - accuracy: 0.8350 - val_loss: 0.3481 - val_accuracy: 0.8984\n",
            "Epoch 5/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.3480 - accuracy: 0.8821 - val_loss: 0.2653 - val_accuracy: 0.9246\n",
            "Epoch 6/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.2648 - accuracy: 0.9142 - val_loss: 0.1877 - val_accuracy: 0.9447\n",
            "Epoch 7/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.2067 - accuracy: 0.9303 - val_loss: 0.1378 - val_accuracy: 0.9581\n",
            "Epoch 8/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.1674 - accuracy: 0.9441 - val_loss: 0.1256 - val_accuracy: 0.9653\n",
            "Epoch 9/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.1353 - accuracy: 0.9555 - val_loss: 0.1041 - val_accuracy: 0.9676\n",
            "Epoch 10/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.1155 - accuracy: 0.9634 - val_loss: 0.1024 - val_accuracy: 0.9701\n",
            "Epoch 11/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.1142 - accuracy: 0.9624 - val_loss: 0.0660 - val_accuracy: 0.9810\n",
            "Epoch 12/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0820 - accuracy: 0.9738 - val_loss: 0.0779 - val_accuracy: 0.9732\n",
            "Epoch 13/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0728 - accuracy: 0.9770 - val_loss: 0.0521 - val_accuracy: 0.9861\n",
            "Epoch 14/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0734 - accuracy: 0.9775 - val_loss: 0.0608 - val_accuracy: 0.9794\n",
            "Epoch 15/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0655 - accuracy: 0.9790 - val_loss: 0.0539 - val_accuracy: 0.9853\n",
            "Epoch 16/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0555 - accuracy: 0.9824 - val_loss: 0.0444 - val_accuracy: 0.9848\n",
            "Epoch 17/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0560 - accuracy: 0.9810 - val_loss: 0.0539 - val_accuracy: 0.9858\n",
            "Epoch 18/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.0526 - val_accuracy: 0.9838\n",
            "Epoch 19/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0427 - accuracy: 0.9864 - val_loss: 0.0437 - val_accuracy: 0.9884\n",
            "Epoch 20/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0543 - accuracy: 0.9833 - val_loss: 0.0350 - val_accuracy: 0.9900\n",
            "Epoch 21/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.0431 - val_accuracy: 0.9856\n",
            "Epoch 22/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0410 - accuracy: 0.9867 - val_loss: 0.0332 - val_accuracy: 0.9915\n",
            "Epoch 23/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0334 - accuracy: 0.9898 - val_loss: 0.0316 - val_accuracy: 0.9902\n",
            "Epoch 24/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0305 - accuracy: 0.9907 - val_loss: 0.0517 - val_accuracy: 0.9825\n",
            "Epoch 25/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9891 - val_loss: 0.0314 - val_accuracy: 0.9905\n",
            "Epoch 26/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0410 - accuracy: 0.9872 - val_loss: 0.0406 - val_accuracy: 0.9864\n",
            "Epoch 27/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.0312 - val_accuracy: 0.9900\n",
            "Epoch 28/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.0514 - val_accuracy: 0.9817\n",
            "Epoch 29/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0399 - accuracy: 0.9869 - val_loss: 0.0404 - val_accuracy: 0.9887\n",
            "Epoch 30/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.0304 - val_accuracy: 0.9915\n",
            "Epoch 31/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0309 - accuracy: 0.9900 - val_loss: 0.0321 - val_accuracy: 0.9907\n",
            "Epoch 32/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0306 - val_accuracy: 0.9902\n",
            "Epoch 33/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0257 - val_accuracy: 0.9907\n",
            "Epoch 34/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0302 - val_accuracy: 0.9905\n",
            "Epoch 35/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 0.0421 - val_accuracy: 0.9879\n",
            "Epoch 36/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.0388 - val_accuracy: 0.9876\n",
            "Epoch 37/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0357 - val_accuracy: 0.9900\n",
            "Epoch 38/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0284 - val_accuracy: 0.9918\n",
            "Epoch 39/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.0380 - val_accuracy: 0.9882\n",
            "Epoch 40/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0204 - accuracy: 0.9945 - val_loss: 0.0340 - val_accuracy: 0.9902\n",
            "Epoch 41/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0311 - val_accuracy: 0.9902\n",
            "Epoch 42/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0220 - val_accuracy: 0.9920\n",
            "Epoch 43/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.0393 - val_accuracy: 0.9884\n",
            "Epoch 44/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0284 - val_accuracy: 0.9905\n",
            "Epoch 45/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.0398 - val_accuracy: 0.9884\n",
            "Epoch 46/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0175 - accuracy: 0.9938 - val_loss: 0.0264 - val_accuracy: 0.9925\n",
            "Epoch 47/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0270 - val_accuracy: 0.9913\n",
            "Epoch 48/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0295 - val_accuracy: 0.9910\n",
            "Epoch 49/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0158 - accuracy: 0.9947 - val_loss: 0.0383 - val_accuracy: 0.9884\n",
            "Epoch 50/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.0393 - val_accuracy: 0.9894\n",
            "Epoch 51/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0341 - accuracy: 0.9890 - val_loss: 0.0313 - val_accuracy: 0.9900\n",
            "Epoch 52/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.0272 - val_accuracy: 0.9933\n",
            "Epoch 53/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.0318 - val_accuracy: 0.9887\n",
            "Epoch 54/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0315 - val_accuracy: 0.9913\n",
            "Epoch 55/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0264 - val_accuracy: 0.9920\n",
            "Epoch 56/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0189 - accuracy: 0.9942 - val_loss: 0.0299 - val_accuracy: 0.9925\n",
            "Epoch 57/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0242 - val_accuracy: 0.9923\n",
            "Epoch 58/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0275 - val_accuracy: 0.9943\n",
            "Epoch 59/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 0.0257 - val_accuracy: 0.9918\n",
            "Epoch 60/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.0273 - val_accuracy: 0.9928\n",
            "Epoch 61/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0277 - val_accuracy: 0.9915\n",
            "Epoch 62/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0215 - val_accuracy: 0.9918\n",
            "Epoch 63/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.0282 - val_accuracy: 0.9910\n",
            "Epoch 64/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0203 - val_accuracy: 0.9933\n",
            "Epoch 65/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.0405 - val_accuracy: 0.9897\n",
            "Epoch 66/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0283 - val_accuracy: 0.9923\n",
            "Epoch 67/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.0412 - val_accuracy: 0.9913\n",
            "Epoch 68/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0303 - val_accuracy: 0.9928\n",
            "Epoch 69/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0252 - val_accuracy: 0.9923\n",
            "Epoch 70/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.0505 - val_accuracy: 0.9866\n",
            "Epoch 71/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0425 - val_accuracy: 0.9894\n",
            "Epoch 72/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0708 - val_accuracy: 0.9786\n",
            "Epoch 73/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 0.0177 - val_accuracy: 0.9938\n",
            "Epoch 74/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0241 - val_accuracy: 0.9933\n",
            "Epoch 75/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0224 - val_accuracy: 0.9920\n",
            "Epoch 76/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0298 - val_accuracy: 0.9943\n",
            "Epoch 77/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 0.0366 - val_accuracy: 0.9931\n",
            "Epoch 78/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0338 - val_accuracy: 0.9933\n",
            "Epoch 79/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0352 - val_accuracy: 0.9923\n",
            "Epoch 80/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0382 - val_accuracy: 0.9902\n",
            "Epoch 81/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0230 - val_accuracy: 0.9928\n",
            "Epoch 82/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0214 - val_accuracy: 0.9933\n",
            "Epoch 83/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0087 - accuracy: 0.9976 - val_loss: 0.0289 - val_accuracy: 0.9933\n",
            "Epoch 84/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.0333 - val_accuracy: 0.9907\n",
            "Epoch 85/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0274 - val_accuracy: 0.9936\n",
            "Epoch 86/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0444 - val_accuracy: 0.9907\n",
            "Epoch 87/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.0489 - val_accuracy: 0.9887\n",
            "Epoch 88/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.0374 - val_accuracy: 0.9907\n",
            "Epoch 89/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9953 - val_loss: 0.0359 - val_accuracy: 0.9910\n",
            "Epoch 90/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.0427 - val_accuracy: 0.9900\n",
            "Epoch 91/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.0379 - val_accuracy: 0.9910\n",
            "Epoch 92/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0348 - val_accuracy: 0.9905\n",
            "Epoch 93/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.0225 - val_accuracy: 0.9938\n",
            "Epoch 94/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0313 - val_accuracy: 0.9933\n",
            "Epoch 95/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0430 - val_accuracy: 0.9907\n",
            "Epoch 96/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0208 - accuracy: 0.9944 - val_loss: 0.0400 - val_accuracy: 0.9920\n",
            "Epoch 97/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.0414 - val_accuracy: 0.9910\n",
            "Epoch 98/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0322 - val_accuracy: 0.9938\n",
            "Epoch 99/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0322 - val_accuracy: 0.9949\n",
            "Epoch 100/100\n",
            "122/122 [==============================] - 1s 8ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0364 - val_accuracy: 0.9936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMvB1MOEOxVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting loss/accuracy values of train and validation data during training model\n",
        "def plot_loss_accuracy(epochs, history):\n",
        "  plt.figure(figsize=(10, 4))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.title('Loss')\n",
        "  plt.plot(np.arange(0, epochs), history.history['loss'], label='train')\n",
        "  plt.plot(np.arange(0, epochs), history.history['val_loss'], label='val')\n",
        "  plt.legend(loc='best')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.title('Accuracy')\n",
        "  plt.plot(np.arange(0, epochs), history.history['accuracy'], label='train')\n",
        "  plt.plot(np.arange(0, epochs), history.history['val_accuracy'], label='val')\n",
        "  plt.legend(loc='best')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcctqhYsO949",
        "colab_type": "text"
      },
      "source": [
        "Na sledećem zajedničkom grafiku je prikazana funkcija gubitka na skupu za treniranje i validaciju, a potom i funkcija preciznosti."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-IoL8rjM9IK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "3a5838c9-dfd3-4f0e-c34f-5156976bf032"
      },
      "source": [
        "plot_loss_accuracy(100, history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-gVsg_qO3-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_classification_report(model, X_test, y_test):\n",
        "  print(classification_report(np.argmax(y_test, axis=1), model.predict_classes(X_test)))"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L53ZSIlMPAI7",
        "colab_type": "text"
      },
      "source": [
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHUH3ePbND3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "5d5f6717-eafe-4d03-e1e2-3743fd0b844f"
      },
      "source": [
        "show_classification_report(model, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       330\n",
            "           1       1.00      1.00      1.00       330\n",
            "           2       1.00      1.00      1.00       330\n",
            "           3       0.98      1.00      0.99       330\n",
            "           4       0.99      0.97      0.98       330\n",
            "           5       1.00      1.00      1.00       330\n",
            "           6       0.99      0.99      0.99       330\n",
            "           7       0.99      0.99      0.99       330\n",
            "           8       0.99      1.00      1.00       330\n",
            "           9       0.99      0.99      0.99       330\n",
            "          10       0.99      0.98      0.99       330\n",
            "          11       1.00      1.00      1.00       330\n",
            "          12       1.00      1.00      1.00       330\n",
            "          13       1.00      1.00      1.00       330\n",
            "          14       1.00      0.98      0.99       330\n",
            "          15       1.00      0.99      0.99       330\n",
            "          16       1.00      1.00      1.00       330\n",
            "          17       0.98      0.99      0.99       330\n",
            "          18       1.00      0.98      0.99       330\n",
            "          19       0.99      0.99      0.99       330\n",
            "          20       0.99      1.00      1.00       330\n",
            "          21       0.99      0.99      0.99       330\n",
            "          22       0.99      1.00      1.00       330\n",
            "          23       0.98      0.99      0.99       330\n",
            "          24       1.00      1.00      1.00       330\n",
            "          25       1.00      1.00      1.00       330\n",
            "          26       1.00      1.00      1.00       330\n",
            "          27       1.00      1.00      1.00       330\n",
            "          28       1.00      1.00      1.00       330\n",
            "\n",
            "    accuracy                           0.99      9570\n",
            "   macro avg       0.99      0.99      0.99      9570\n",
            "weighted avg       0.99      0.99      0.99      9570\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0LtNhuPJrmq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1cb1591c-1e50-4ef7-971f-8e1c89936a9c"
      },
      "source": [
        "# Evaluate model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.03432227671146393\n",
            "Test accuracy: 0.9936259388923645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4UK03p14WnA",
        "colab_type": "text"
      },
      "source": [
        "**Model iz naučnog rada**  \n",
        "Sledeći pokušaj rešavanja datog problema je bio uz pomoć pronađenog naučnog rada koji možete pogledati [ovde](https://) .  \n",
        "Iako se skupovi podataka razlikuju, pokušali smo sa predloženim modelom: korišćena je neuronska mreža sa propagacijom unapred, gde se dodaju sledeći slojevi:  \n",
        "**1 sloj:** Konvolucioni sloj sa *16* filtera, kernelom veličine *2x2* i *ReLu* aktivacionom funkcijom.    \n",
        "**2 sloj:** Agregacioni sloj koji vrši redukciju slojeva svođenjem blokova zadatih večina na njihove maksimalne vrednosti, veličinom bloka *2x2*, veličinom pomeraja *2x2* i uokvirenjem tako da veličina izlazne slike može biti istih dimenzija.  \n",
        "**3 sloj:** Konvolucioni sloj sa *32* filtera, kernelom veličine *3x3* i *ReLu* aktivacionom funkcijom.    \n",
        "**4 sloj:** Agregacioni sloj koji vrši redukciju slojeva svođenjem blokova zadatih večina na njihove maksimalne vrednosti, veličinom bloka *3x3*, veličinom pomeraja *3x3* i uokvirenjem tako da veličina izlazne slike može biti istih dimenzija.   \n",
        "**5 sloj:** Konvolucioni sloj sa *64* filtera, kernelom veličine *5x5* i *ReLu* aktivacionom funkcijom.  \n",
        "Zatim funkcija koja se koristi za transformisanje matrica u vektore *Flatten*.    \n",
        "**6 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *128* i ReLu aktivacionom funkcijom.  \n",
        "Zatim tehnika regularizacije kojom isključujemo nasumično odabrane neurone i omogućavamo drugačiji protok podataka kroz mrežu *Dropout*.\n",
        "**7 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *30* i *softmax* aktivacionom funkcijom. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yuu1teNtptw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DOBAR MODEL ZA GRAYSCALE\n",
        "# Training model\n",
        "paper_model = Sequential()\n",
        "paper_model.add(Conv2D(16, (2,2), input_shape=(50,50,1), activation='relu'))\n",
        "paper_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "paper_model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "paper_model.add(MaxPooling2D(pool_size=(3, 3), strides=(3, 3), padding='same'))\n",
        "paper_model.add(Conv2D(64, (5,5), activation='relu'))\n",
        "paper_model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
        "paper_model.add(Flatten())\n",
        "paper_model.add(Dense(128, activation='relu'))\n",
        "paper_model.add(Dropout(0.2))\n",
        "paper_model.add(Dense(numOfClasses, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMnkfO3zpub1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "685b37f1-44ba-432a-8e78-a3387ba5b8e8"
      },
      "source": [
        "# Model summary per layers\n",
        "paper_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_32 (Conv2D)           (None, 49, 49, 16)        80        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 23, 23, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 4, 4, 64)          51264     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 1, 1, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 30)                3870      \n",
            "=================================================================\n",
            "Total params: 68,174\n",
            "Trainable params: 68,174\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43SBuO_W2Sg-",
        "colab_type": "text"
      },
      "source": [
        "**Mrežu ćemo trenirati prema sledećim smernicama:**  \n",
        "*Funkcija greške*: Kategorička unakrsna entropija  \n",
        "*Optimizator*: Adam sa korakom učenja **0.001**   \n",
        "*Broj epoha*: **50**  \n",
        "*Veličina paketića za treniranje* (engl. batch size): **500**  \n",
        "\n",
        "Za evaluaciju mreže koristimo **preciznost**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_theT_fp3Wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paper_model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XAYppvJp7AH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa1c7699-81c0-41ce-8fc3-0cf3f390b045"
      },
      "source": [
        "# Train model\n",
        "paper_history = paper_model.fit(X_train, y_train,\n",
        "                    batch_size=500,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2, \n",
        "                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 3.3796 - accuracy: 0.0472 - val_loss: 3.3201 - val_accuracy: 0.0983\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 3.1955 - accuracy: 0.1105 - val_loss: 2.9264 - val_accuracy: 0.1837\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 2.7575 - accuracy: 0.2005 - val_loss: 2.4065 - val_accuracy: 0.3222\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 2.3018 - accuracy: 0.3143 - val_loss: 2.0393 - val_accuracy: 0.3994\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 2.0255 - accuracy: 0.3742 - val_loss: 1.7910 - val_accuracy: 0.4725\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.8052 - accuracy: 0.4366 - val_loss: 1.6066 - val_accuracy: 0.5167\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.6260 - accuracy: 0.4871 - val_loss: 1.4595 - val_accuracy: 0.5674\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.4950 - accuracy: 0.5282 - val_loss: 1.3290 - val_accuracy: 0.6034\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 1.3650 - accuracy: 0.5614 - val_loss: 1.2269 - val_accuracy: 0.6392\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.2630 - accuracy: 0.6000 - val_loss: 1.1156 - val_accuracy: 0.6706\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.1709 - accuracy: 0.6211 - val_loss: 1.0281 - val_accuracy: 0.6922\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.0974 - accuracy: 0.6464 - val_loss: 1.0643 - val_accuracy: 0.6541\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 1.0412 - accuracy: 0.6633 - val_loss: 0.9475 - val_accuracy: 0.7059\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.9757 - accuracy: 0.6859 - val_loss: 0.8946 - val_accuracy: 0.7159\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.9183 - accuracy: 0.6978 - val_loss: 0.8816 - val_accuracy: 0.7252\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.8965 - accuracy: 0.7081 - val_loss: 0.8106 - val_accuracy: 0.7481\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.8412 - accuracy: 0.7249 - val_loss: 0.7467 - val_accuracy: 0.7674\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.7850 - accuracy: 0.7450 - val_loss: 0.7156 - val_accuracy: 0.7761\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.7496 - accuracy: 0.7557 - val_loss: 0.6892 - val_accuracy: 0.7810\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.7098 - accuracy: 0.7688 - val_loss: 0.6954 - val_accuracy: 0.7741\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6934 - accuracy: 0.7717 - val_loss: 0.6063 - val_accuracy: 0.8145\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6526 - accuracy: 0.7837 - val_loss: 0.5840 - val_accuracy: 0.8237\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6461 - accuracy: 0.7824 - val_loss: 0.6100 - val_accuracy: 0.8067\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.6324 - accuracy: 0.7917 - val_loss: 0.5719 - val_accuracy: 0.8219\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5887 - accuracy: 0.8063 - val_loss: 0.5217 - val_accuracy: 0.8379\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5527 - accuracy: 0.8192 - val_loss: 0.6434 - val_accuracy: 0.7877\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5504 - accuracy: 0.8163 - val_loss: 0.5712 - val_accuracy: 0.8152\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5442 - accuracy: 0.8183 - val_loss: 0.5265 - val_accuracy: 0.8327\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.5096 - accuracy: 0.8298 - val_loss: 0.4642 - val_accuracy: 0.8546\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4854 - accuracy: 0.8365 - val_loss: 0.4662 - val_accuracy: 0.8536\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4662 - accuracy: 0.8456 - val_loss: 0.4203 - val_accuracy: 0.8760\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.4547 - accuracy: 0.8506 - val_loss: 0.4413 - val_accuracy: 0.8562\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4472 - accuracy: 0.8504 - val_loss: 0.4103 - val_accuracy: 0.8700\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4277 - accuracy: 0.8559 - val_loss: 0.4054 - val_accuracy: 0.8749\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.4241 - accuracy: 0.8589 - val_loss: 0.3907 - val_accuracy: 0.8798\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.4011 - accuracy: 0.8657 - val_loss: 0.3707 - val_accuracy: 0.8845\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3883 - accuracy: 0.8723 - val_loss: 0.4004 - val_accuracy: 0.8621\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3930 - accuracy: 0.8665 - val_loss: 0.4115 - val_accuracy: 0.8618\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3843 - accuracy: 0.8708 - val_loss: 0.3703 - val_accuracy: 0.8837\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3642 - accuracy: 0.8785 - val_loss: 0.3614 - val_accuracy: 0.8850\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3510 - accuracy: 0.8809 - val_loss: 0.3289 - val_accuracy: 0.8911\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.8911 - val_loss: 0.3665 - val_accuracy: 0.8762\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3500 - accuracy: 0.8834 - val_loss: 0.3179 - val_accuracy: 0.8984\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3193 - accuracy: 0.8951 - val_loss: 0.3158 - val_accuracy: 0.9007\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3202 - accuracy: 0.8928 - val_loss: 0.3130 - val_accuracy: 0.9012\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3236 - accuracy: 0.8929 - val_loss: 0.3480 - val_accuracy: 0.8881\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3171 - accuracy: 0.8941 - val_loss: 0.3085 - val_accuracy: 0.8996\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.2981 - accuracy: 0.9020 - val_loss: 0.2974 - val_accuracy: 0.9074\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3088 - accuracy: 0.8933 - val_loss: 0.3269 - val_accuracy: 0.8963\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.3201 - accuracy: 0.8919 - val_loss: 0.3098 - val_accuracy: 0.8978\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2803 - accuracy: 0.9067 - val_loss: 0.2902 - val_accuracy: 0.9115\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.2671 - accuracy: 0.9122 - val_loss: 0.2670 - val_accuracy: 0.9182\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2669 - accuracy: 0.9114 - val_loss: 0.2809 - val_accuracy: 0.9120\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2554 - accuracy: 0.9171 - val_loss: 0.2524 - val_accuracy: 0.9161\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2564 - accuracy: 0.9148 - val_loss: 0.2574 - val_accuracy: 0.9223\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2463 - accuracy: 0.9191 - val_loss: 0.3118 - val_accuracy: 0.9009\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2615 - accuracy: 0.9119 - val_loss: 0.2559 - val_accuracy: 0.9153\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2378 - accuracy: 0.9191 - val_loss: 0.2492 - val_accuracy: 0.9200\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2289 - accuracy: 0.9236 - val_loss: 0.2255 - val_accuracy: 0.9328\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2222 - accuracy: 0.9247 - val_loss: 0.2412 - val_accuracy: 0.9238\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2541 - accuracy: 0.9117 - val_loss: 0.2685 - val_accuracy: 0.9122\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2191 - accuracy: 0.9282 - val_loss: 0.2292 - val_accuracy: 0.9279\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2167 - accuracy: 0.9266 - val_loss: 0.2238 - val_accuracy: 0.9285\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2037 - accuracy: 0.9323 - val_loss: 0.2348 - val_accuracy: 0.9241\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1966 - accuracy: 0.9339 - val_loss: 0.2046 - val_accuracy: 0.9395\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1919 - accuracy: 0.9369 - val_loss: 0.2325 - val_accuracy: 0.9269\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1989 - accuracy: 0.9337 - val_loss: 0.2403 - val_accuracy: 0.9207\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1970 - accuracy: 0.9366 - val_loss: 0.2112 - val_accuracy: 0.9364\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1849 - accuracy: 0.9388 - val_loss: 0.2244 - val_accuracy: 0.9259\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.2012 - accuracy: 0.9323 - val_loss: 0.1966 - val_accuracy: 0.9408\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1692 - accuracy: 0.9460 - val_loss: 0.2204 - val_accuracy: 0.9272\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1761 - accuracy: 0.9413 - val_loss: 0.2136 - val_accuracy: 0.9326\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1828 - accuracy: 0.9383 - val_loss: 0.1926 - val_accuracy: 0.9367\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1716 - accuracy: 0.9426 - val_loss: 0.2153 - val_accuracy: 0.9292\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1790 - accuracy: 0.9392 - val_loss: 0.2085 - val_accuracy: 0.9303\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1954 - accuracy: 0.9308 - val_loss: 0.1877 - val_accuracy: 0.9406\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1575 - accuracy: 0.9492 - val_loss: 0.1940 - val_accuracy: 0.9370\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1592 - accuracy: 0.9469 - val_loss: 0.1823 - val_accuracy: 0.9470\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1484 - accuracy: 0.9496 - val_loss: 0.1697 - val_accuracy: 0.9493\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1443 - accuracy: 0.9521 - val_loss: 0.1808 - val_accuracy: 0.9449\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1424 - accuracy: 0.9541 - val_loss: 0.2036 - val_accuracy: 0.9382\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1496 - accuracy: 0.9481 - val_loss: 0.1829 - val_accuracy: 0.9457\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1373 - accuracy: 0.9552 - val_loss: 0.1943 - val_accuracy: 0.9403\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1531 - accuracy: 0.9482 - val_loss: 0.1813 - val_accuracy: 0.9413\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1391 - accuracy: 0.9548 - val_loss: 0.1775 - val_accuracy: 0.9413\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1408 - accuracy: 0.9535 - val_loss: 0.1665 - val_accuracy: 0.9498\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1254 - accuracy: 0.9590 - val_loss: 0.1660 - val_accuracy: 0.9444\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1294 - accuracy: 0.9595 - val_loss: 0.1548 - val_accuracy: 0.9547\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1210 - accuracy: 0.9629 - val_loss: 0.1473 - val_accuracy: 0.9550\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1228 - accuracy: 0.9591 - val_loss: 0.1953 - val_accuracy: 0.9385\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1265 - accuracy: 0.9590 - val_loss: 0.1729 - val_accuracy: 0.9454\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1313 - accuracy: 0.9586 - val_loss: 0.1599 - val_accuracy: 0.9496\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1318 - accuracy: 0.9541 - val_loss: 0.2851 - val_accuracy: 0.9143\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1418 - accuracy: 0.9533 - val_loss: 0.1509 - val_accuracy: 0.9534\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1093 - accuracy: 0.9658 - val_loss: 0.1445 - val_accuracy: 0.9545\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1077 - accuracy: 0.9632 - val_loss: 0.1544 - val_accuracy: 0.9529\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1193 - accuracy: 0.9590 - val_loss: 0.1463 - val_accuracy: 0.9552\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1165 - accuracy: 0.9611 - val_loss: 0.1515 - val_accuracy: 0.9524\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1397 - accuracy: 0.9534 - val_loss: 0.1700 - val_accuracy: 0.9465\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.1083 - accuracy: 0.9637 - val_loss: 0.1461 - val_accuracy: 0.9508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUCKQEKePHPd",
        "colab_type": "text"
      },
      "source": [
        "*Na sledećem zajedničkom grafiku je prikazana funkcija gubitka na skupu za treniranje i validaciju, a potom i funkcija preciznosti.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThoWY61PNayM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_loss_accuracy(50, paper_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03yixKaoPInN",
        "colab_type": "text"
      },
      "source": [
        "**TODO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PocJ2jw7NeJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_classification_report(paper_model, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dZonTRYMgE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57f8244c-9cbb-4453-b515-fa67f94f2a10"
      },
      "source": [
        "# Evaluate model\n",
        "score = paper_model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.15175390243530273\n",
            "Test accuracy: 0.9547544121742249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXZUrMWKW9e3",
        "colab_type": "text"
      },
      "source": [
        "**VGG16 model**  \n",
        "Sledeći pokušaj rešavanja datog problema je bio uz pomoć arhitekture VGG16 mreže. Korišćena je neuronska mreža sa propagacijom unapred, gde se dodaju sledeći slojevi:  \n",
        "**1 sloj:** Konvolucioni sloj sa *64* filtera, kernelom veličine *3x3*, okvirenjem tako da veličina izlazne slike može biti istih dimenzija i *ReLu* aktivacionom funkcijom.  \n",
        "**2 sloj:** Kao i prvi sloj.  \n",
        "**3 sloj:** Agregacioni sloj koji vrši redukciju slojeva svođenjem blokova zadatih večina na njihove maksimalne vrednosti, veličinom bloka *2x2*, veličinom pomeraja *2x2*.  \n",
        "**4 sloj:** Konvolucioni sloj sa *128* filtera, kernelom veličine *3x3*, okvirenjem tako da veličina izlazne slike može biti istih dimenzija i *ReLu* aktivacionom funkcijom.  \n",
        "**5 sloj:** Kao i četvrti sloj.   \n",
        "**6 sloj:** Kao i treći sloj.     \n",
        "**7 sloj:** Konvolucioni sloj sa *256* filtera, kernelom veličine *3x3*, okvirenjem tako da veličina izlazne slike može biti istih dimenzija i *ReLu* aktivacionom funkcijom.  \n",
        "**8 sloj:** Kao i sedmi sloj.  \n",
        "**9 sloj:** Kao i sedmi sloj.  \n",
        "**10 sloj:** Konvolucioni sloj sa *512* filtera, kernelom veličine *3x3*, okvirenjem tako da veličina izlazne slike može biti istih dimenzija i *ReLu* aktivacionom funkcijom.  \n",
        "**11 sloj:** Kao i deseti sloj.  \n",
        "**12 sloj:** Kao i deseti sloj.\n",
        "**13 sloj:** Kao i treći sloj.  \n",
        "**14 sloj:** Kao i deseti sloj.  \n",
        "**15 sloj:** Kao i deseti sloj.  \n",
        "**16 sloj:** Kao i deseti sloj.  \n",
        "**17 sloj:** Kao i treći sloj.  \n",
        "Zatim funkcija koja se koristi za transformisanje matrica u vektore *Flatten*.  \n",
        "**18 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *4096* i *ReLu* aktivacionom funkcijom. \n",
        "**19 sloj:** Kao i 18. sloj.  \n",
        "**20 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *30* i *softmax* aktivacionom funkcijom. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFDwLlWkW8yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG16 model\n",
        "vgg16_model = Sequential()\n",
        "\n",
        "vgg16_model.add(Conv2D(input_shape=(200,200,3), filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "vgg16_model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "vgg16_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "vgg16_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "vgg16_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vgg16_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "vgg16_model.add(Flatten())\n",
        "vgg16_model.add(Dense(units=4096, activation=\"relu\"))\n",
        "vgg16_model.add(Dense(units=4096, activation=\"relu\"))\n",
        "vgg16_model.add(Dense(units=numOfClasses, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFyRQ8KMZ296",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model summary per layers\n",
        "vgg16_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJr1es1UaJe3",
        "colab_type": "text"
      },
      "source": [
        "**Mrežu ćemo trenirati prema sledećim smernicama:**  \n",
        "*Funkcija greške*: Kategorička unakrsna entropija  \n",
        "*Optimizator*: Adam sa korakom učenja **0.001**   \n",
        "*Broj epoha*: **100**  \n",
        "*Veličina paketića za treniranje* (engl. batch size): **128**  \n",
        "\n",
        "Za evaluaciju mreže koristimo **preciznost**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrSNem6yaJrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiEIFhPkaRhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg16_history = vgg16_model.fit(X_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2, \n",
        "                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWMQuu4dajyW",
        "colab_type": "text"
      },
      "source": [
        "*Na sledećem zajedničkom grafiku je prikazana funkcija gubitka na skupu za treniranje i validaciju, a potom i funkcija preciznosti.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_aBdqMai--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_loss_accuracy(100, vgg16_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKxyINCnar1J",
        "colab_type": "text"
      },
      "source": [
        "**TODO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obx9gj76at5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_classification_report(vgg16_model, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJBL411jaxY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate model\n",
        "score = vgg16_model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVajeI9Cbndr",
        "colab_type": "text"
      },
      "source": [
        "**AlexNet model**  \n",
        "TODO : OPET OVO ISPISATI - KORISTI SAJT\n",
        "Sledeći pokušaj rešavanja datog problema je bio uz pomoć arhitekture AlexNet mreže. Korišćena je neuronska mreža sa propagacijom unapred, gde se dodaju sledeći slojevi:  \n",
        "**1 sloj:** Konvolucioni sloj sa *96* filtera, kernelom veličine *11x11*, veličinom pomeraja *4x4* i *ReLu* aktivacionom funkcijom.  \n",
        "**2 sloj:** Agregacioni sloj koji vrši redukciju slojeva svođenjem blokova zadatih večina na njihove maksimalne vrednosti, veličinom bloka *2x2*, veličinom pomeraja *2x2*.  \n",
        "**3 sloj:** Konvolucioni sloj sa *256* filtera, kernelom veličine *11x11*, veličinom pomeraja *1x1* i *ReLu* aktivacionom funkcijom.  \n",
        "**4 sloj:** Kao i drugi sloj.  \n",
        "**5 sloj:** Konvolucioni sloj sa *384* filtera, kernelom veličine *3x3*, veličinom pomeraja *1x1* i *ReLu* aktivacionom funkcijom.   \n",
        "**6 sloj:** Kao i peti sloj.  \n",
        "**7 sloj:** Konvolucioni sloj sa *256* filtera, kernelom veličine *3x3*, veličinom pomeraja *1x1* i *ReLu* aktivacionom funkcijom.   \n",
        "**8 sloj:** Kao i peti sloj.  \n",
        "Zatim funkcija koja se koristi za transformisanje matrica u vektore *Flatten*.   \n",
        "**9 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *4096* i *ReLu* aktivacionom funkcijom.   \n",
        "Zatim funkcija koja se koristi da ne bi došlo do preprilagođavanja podataka *Dropout*.  \n",
        "**10 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *4096* i *ReLu* aktivacionom funkcijom.   \n",
        "Zatim funkcija koja se koristi da ne bi došlo do preprilagođavanja podataka *Dropout*.  \n",
        "**11 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *1000* i *ReLu* aktivacionom funkcijom.   \n",
        "Zatim funkcija koja se koristi da ne bi došlo do preprilagođavanja podataka *Dropout*.  \n",
        "**12 sloj:** Potpuno povezan sloj sa brojem izlaznih neurona *30* i *softmax* aktivacionom funkcijom.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD_A_JBGmTOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOVI ALEXNET MODEL\n",
        "\n",
        "alexnet_model = Sequential()\n",
        "alexnet_model.add(Conv2D(filters=96, input_shape=(50,50,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "alexnet_model.add(BatchNormalization())\n",
        "alexnet_model.add(Activation('relu'))\n",
        "alexnet_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "alexnet_model.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "alexnet_model.add(BatchNormalization())\n",
        "alexnet_model.add(Activation('relu'))\n",
        "alexnet_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "alexnet_model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "alexnet_model.add(BatchNormalization())\n",
        "alexnet_model.add(Activation('relu'))\n",
        "\n",
        "alexnet_model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "alexnet_model.add(BatchNormalization())\n",
        "alexnet_model.add(Activation('relu'))\n",
        "\n",
        "alexnet_model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "alexnet_model.add(BatchNormalization())\n",
        "alexnet_model.add(Activation('relu'))\n",
        "alexnet_model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "alexnet_model.add(Flatten())\n",
        "alexnet_model.add(Dense(4096, input_shape=(50,50,3)))\n",
        "alexnet_model.add(BatchNormalization())\n",
        "alexnet_model.add(Activation('relu'))\n",
        "alexnet_model.add(Dropout(0.4))\n",
        "alexnet_model.add(Dense(4096))\n",
        "alexnet_model.add(BatchNormalization())\n",
        "alexnet_model.add(Activation('relu'))\n",
        "alexnet_model.add(Dropout(0.4))\n",
        "\n",
        "alexnet_model.add(Dense(1000))\n",
        "alexnet_model.add(BatchNormalization())\n",
        "alexnet_model.add(Activation('relu'))\n",
        "alexnet_model.add(Dropout(0.4))\n",
        "\n",
        "alexnet_model.add(Dense(numOfClasses))\n",
        "alexnet_model.add(BatchNormalization())\n",
        "alexnet_model.add(Activation('softmax'))"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wBPFFo19fA6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76f97549-08da-45ec-9a51-61ab03b95d4b"
      },
      "source": [
        "alexnet_model.summary()\n",
        "alexnet_model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_93 (Conv2D)           (None, 13, 13, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_163 (Bat (None, 13, 13, 96)        384       \n",
            "_________________________________________________________________\n",
            "activation_162 (Activation)  (None, 13, 13, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 7, 7, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 7, 7, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_164 (Bat (None, 7, 7, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_163 (Activation)  (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 4, 4, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_165 (Bat (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_164 (Activation)  (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_166 (Bat (None, 4, 4, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_165 (Activation)  (None, 4, 4, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 4, 4, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_167 (Bat (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_166 (Activation)  (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 4096)              4198400   \n",
            "_________________________________________________________________\n",
            "batch_normalization_168 (Bat (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_167 (Activation)  (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_169 (Bat (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_168 (Activation)  (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_170 (Bat (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_169 (Activation)  (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 30)                30030     \n",
            "_________________________________________________________________\n",
            "batch_normalization_171 (Bat (None, 30)                120       \n",
            "_________________________________________________________________\n",
            "activation_170 (Activation)  (None, 30)                0         \n",
            "=================================================================\n",
            "Total params: 28,896,334\n",
            "Trainable params: 28,875,138\n",
            "Non-trainable params: 21,196\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEF_0CHJfEuY",
        "colab_type": "text"
      },
      "source": [
        "**Mrežu ćemo trenirati prema sledećim smernicama:**  \n",
        "*Funkcija greške*: Kategorička unakrsna entropija  \n",
        "*Optimizator*: Adam sa korakom učenja **0.001**   \n",
        "*Broj epoha*: **100**  \n",
        "*Veličina paketića za treniranje* (engl. batch size): **128**  \n",
        "\n",
        "Za evaluaciju mreže koristimo **preciznost**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RoxVfmhfG6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alexnet_model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwrOm_N4ftQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33afe6fa-e9b5-469a-dc78-4b7583e055fe"
      },
      "source": [
        "alex_history_new = alexnet_model.fit(X_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=100,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2, \n",
        "                    shuffle=True)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 2.3693 - accuracy: 0.3154 - val_loss: 3.5502 - val_accuracy: 0.0921\n",
            "Epoch 2/100\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 1.3624 - accuracy: 0.6271 - val_loss: 4.9184 - val_accuracy: 0.1336\n",
            "Epoch 3/100\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.8654 - accuracy: 0.7771 - val_loss: 3.0107 - val_accuracy: 0.3080\n",
            "Epoch 4/100\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.5935 - accuracy: 0.8573 - val_loss: 1.9894 - val_accuracy: 0.4738\n",
            "Epoch 5/100\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.4315 - accuracy: 0.8991 - val_loss: 1.6989 - val_accuracy: 0.5497\n",
            "Epoch 6/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.3501 - accuracy: 0.9208 - val_loss: 1.4555 - val_accuracy: 0.6227\n",
            "Epoch 7/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.2798 - accuracy: 0.9390 - val_loss: 1.0944 - val_accuracy: 0.6994\n",
            "Epoch 8/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.2539 - accuracy: 0.9424 - val_loss: 1.2096 - val_accuracy: 0.6768\n",
            "Epoch 9/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.2116 - accuracy: 0.9546 - val_loss: 0.6351 - val_accuracy: 0.8242\n",
            "Epoch 10/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1805 - accuracy: 0.9619 - val_loss: 0.3461 - val_accuracy: 0.9110\n",
            "Epoch 11/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1639 - accuracy: 0.9651 - val_loss: 2.3701 - val_accuracy: 0.4426\n",
            "Epoch 12/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1546 - accuracy: 0.9678 - val_loss: 1.0532 - val_accuracy: 0.7247\n",
            "Epoch 13/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1381 - accuracy: 0.9701 - val_loss: 0.9509 - val_accuracy: 0.7403\n",
            "Epoch 14/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1212 - accuracy: 0.9756 - val_loss: 1.2987 - val_accuracy: 0.6778\n",
            "Epoch 15/100\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1124 - accuracy: 0.9765 - val_loss: 0.6821 - val_accuracy: 0.8106\n",
            "Epoch 16/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0973 - accuracy: 0.9810 - val_loss: 0.6139 - val_accuracy: 0.8446\n",
            "Epoch 17/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1063 - accuracy: 0.9772 - val_loss: 1.2074 - val_accuracy: 0.7115\n",
            "Epoch 18/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0987 - accuracy: 0.9792 - val_loss: 1.3820 - val_accuracy: 0.6631\n",
            "Epoch 19/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0934 - accuracy: 0.9802 - val_loss: 0.8585 - val_accuracy: 0.7602\n",
            "Epoch 20/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0802 - accuracy: 0.9831 - val_loss: 0.4407 - val_accuracy: 0.8785\n",
            "Epoch 21/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0861 - accuracy: 0.9815 - val_loss: 1.5659 - val_accuracy: 0.6408\n",
            "Epoch 22/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0741 - accuracy: 0.9838 - val_loss: 0.7823 - val_accuracy: 0.7972\n",
            "Epoch 23/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0689 - accuracy: 0.9866 - val_loss: 1.3555 - val_accuracy: 0.6850\n",
            "Epoch 24/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0709 - accuracy: 0.9855 - val_loss: 0.3056 - val_accuracy: 0.9241\n",
            "Epoch 25/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0783 - accuracy: 0.9822 - val_loss: 0.3977 - val_accuracy: 0.8963\n",
            "Epoch 26/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0486 - accuracy: 0.9916 - val_loss: 0.3569 - val_accuracy: 0.9035\n",
            "Epoch 27/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0572 - accuracy: 0.9883 - val_loss: 0.4666 - val_accuracy: 0.8886\n",
            "Epoch 28/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0571 - accuracy: 0.9876 - val_loss: 0.4061 - val_accuracy: 0.8953\n",
            "Epoch 29/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0485 - accuracy: 0.9899 - val_loss: 0.8110 - val_accuracy: 0.7985\n",
            "Epoch 30/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0393 - accuracy: 0.9923 - val_loss: 0.1440 - val_accuracy: 0.9609\n",
            "Epoch 31/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0553 - accuracy: 0.9882 - val_loss: 0.7303 - val_accuracy: 0.8024\n",
            "Epoch 32/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0508 - accuracy: 0.9879 - val_loss: 1.5267 - val_accuracy: 0.6742\n",
            "Epoch 33/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0826 - accuracy: 0.9795 - val_loss: 1.4833 - val_accuracy: 0.6529\n",
            "Epoch 34/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0372 - accuracy: 0.9921 - val_loss: 0.9679 - val_accuracy: 0.7476\n",
            "Epoch 35/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0466 - accuracy: 0.9896 - val_loss: 1.0949 - val_accuracy: 0.7102\n",
            "Epoch 36/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0522 - accuracy: 0.9885 - val_loss: 0.4862 - val_accuracy: 0.8742\n",
            "Epoch 37/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0600 - accuracy: 0.9865 - val_loss: 0.2774 - val_accuracy: 0.9156\n",
            "Epoch 38/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0319 - accuracy: 0.9939 - val_loss: 0.1056 - val_accuracy: 0.9748\n",
            "Epoch 39/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0402 - accuracy: 0.9913 - val_loss: 0.6978 - val_accuracy: 0.8111\n",
            "Epoch 40/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0255 - accuracy: 0.9941 - val_loss: 0.9092 - val_accuracy: 0.8114\n",
            "Epoch 41/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0285 - accuracy: 0.9940 - val_loss: 0.2635 - val_accuracy: 0.9264\n",
            "Epoch 42/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0352 - accuracy: 0.9920 - val_loss: 0.4011 - val_accuracy: 0.8837\n",
            "Epoch 43/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0384 - accuracy: 0.9914 - val_loss: 0.8109 - val_accuracy: 0.7957\n",
            "Epoch 44/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0452 - accuracy: 0.9897 - val_loss: 0.5889 - val_accuracy: 0.8438\n",
            "Epoch 45/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0348 - accuracy: 0.9916 - val_loss: 0.4287 - val_accuracy: 0.8865\n",
            "Epoch 46/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0181 - accuracy: 0.9968 - val_loss: 0.0911 - val_accuracy: 0.9753\n",
            "Epoch 47/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0205 - accuracy: 0.9959 - val_loss: 1.5793 - val_accuracy: 0.6420\n",
            "Epoch 48/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0359 - accuracy: 0.9922 - val_loss: 0.4082 - val_accuracy: 0.9012\n",
            "Epoch 49/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0225 - accuracy: 0.9953 - val_loss: 0.4936 - val_accuracy: 0.8706\n",
            "Epoch 50/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0361 - accuracy: 0.9909 - val_loss: 0.2219 - val_accuracy: 0.9385\n",
            "Epoch 51/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0264 - accuracy: 0.9943 - val_loss: 0.7326 - val_accuracy: 0.8147\n",
            "Epoch 52/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0497 - accuracy: 0.9884 - val_loss: 1.5885 - val_accuracy: 0.6547\n",
            "Epoch 53/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0225 - accuracy: 0.9956 - val_loss: 0.3973 - val_accuracy: 0.9025\n",
            "Epoch 54/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0244 - accuracy: 0.9949 - val_loss: 0.6774 - val_accuracy: 0.8433\n",
            "Epoch 55/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0265 - accuracy: 0.9938 - val_loss: 0.3975 - val_accuracy: 0.8973\n",
            "Epoch 56/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0322 - accuracy: 0.9926 - val_loss: 0.4676 - val_accuracy: 0.8767\n",
            "Epoch 57/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0229 - accuracy: 0.9953 - val_loss: 0.2460 - val_accuracy: 0.9367\n",
            "Epoch 58/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 0.1609 - val_accuracy: 0.9524\n",
            "Epoch 59/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0199 - accuracy: 0.9962 - val_loss: 0.8708 - val_accuracy: 0.7931\n",
            "Epoch 60/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0315 - accuracy: 0.9927 - val_loss: 1.1573 - val_accuracy: 0.7203\n",
            "Epoch 61/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0215 - accuracy: 0.9952 - val_loss: 0.4913 - val_accuracy: 0.8685\n",
            "Epoch 62/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0226 - accuracy: 0.9950 - val_loss: 0.5535 - val_accuracy: 0.8616\n",
            "Epoch 63/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0167 - accuracy: 0.9967 - val_loss: 0.3970 - val_accuracy: 0.9076\n",
            "Epoch 64/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.1396 - val_accuracy: 0.9632\n",
            "Epoch 65/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0170 - accuracy: 0.9969 - val_loss: 0.6050 - val_accuracy: 0.8592\n",
            "Epoch 66/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0228 - accuracy: 0.9947 - val_loss: 1.3800 - val_accuracy: 0.6652\n",
            "Epoch 67/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0215 - accuracy: 0.9957 - val_loss: 0.9586 - val_accuracy: 0.7877\n",
            "Epoch 68/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.0996 - val_accuracy: 0.9730\n",
            "Epoch 69/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0338 - accuracy: 0.9916 - val_loss: 0.4574 - val_accuracy: 0.8857\n",
            "Epoch 70/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.4822 - val_accuracy: 0.8760\n",
            "Epoch 71/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0207 - accuracy: 0.9956 - val_loss: 0.1573 - val_accuracy: 0.9586\n",
            "Epoch 72/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0278 - accuracy: 0.9932 - val_loss: 1.0561 - val_accuracy: 0.7442\n",
            "Epoch 73/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 0.9879 - val_accuracy: 0.7609\n",
            "Epoch 74/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0188 - accuracy: 0.9963 - val_loss: 0.5296 - val_accuracy: 0.8695\n",
            "Epoch 75/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 0.1131 - val_accuracy: 0.9668\n",
            "Epoch 76/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.0110 - val_accuracy: 0.9961\n",
            "Epoch 77/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0074 - accuracy: 0.9985 - val_loss: 0.3707 - val_accuracy: 0.9002\n",
            "Epoch 78/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0200 - accuracy: 0.9959 - val_loss: 0.5217 - val_accuracy: 0.8595\n",
            "Epoch 79/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.3458 - val_accuracy: 0.9207\n",
            "Epoch 80/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0136 - accuracy: 0.9971 - val_loss: 0.2114 - val_accuracy: 0.9403\n",
            "Epoch 81/100\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 0.7230 - val_accuracy: 0.8250\n",
            "Epoch 82/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0133 - accuracy: 0.9968 - val_loss: 0.1660 - val_accuracy: 0.9555\n",
            "Epoch 83/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.8306 - val_accuracy: 0.8024\n",
            "Epoch 84/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0258 - accuracy: 0.9941 - val_loss: 0.0518 - val_accuracy: 0.9861\n",
            "Epoch 85/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.8717 - val_accuracy: 0.7921\n",
            "Epoch 86/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.2263 - val_accuracy: 0.9478\n",
            "Epoch 87/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0072 - accuracy: 0.9984 - val_loss: 0.3066 - val_accuracy: 0.9233\n",
            "Epoch 88/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.2272 - val_accuracy: 0.9470\n",
            "Epoch 89/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0135 - accuracy: 0.9968 - val_loss: 0.5458 - val_accuracy: 0.8693\n",
            "Epoch 90/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.2703 - val_accuracy: 0.9277\n",
            "Epoch 91/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.3582 - val_accuracy: 0.9197\n",
            "Epoch 92/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0494 - val_accuracy: 0.9864\n",
            "Epoch 93/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0371 - accuracy: 0.9921 - val_loss: 0.4702 - val_accuracy: 0.8773\n",
            "Epoch 94/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0205 - accuracy: 0.9959 - val_loss: 0.1700 - val_accuracy: 0.9521\n",
            "Epoch 95/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.8557 - val_accuracy: 0.8191\n",
            "Epoch 96/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 1.2343 - val_accuracy: 0.7236\n",
            "Epoch 97/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0100 - accuracy: 0.9981 - val_loss: 0.0946 - val_accuracy: 0.9738\n",
            "Epoch 98/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 1.2093 - val_accuracy: 0.7249\n",
            "Epoch 99/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.0591 - val_accuracy: 0.9810\n",
            "Epoch 100/100\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0217 - val_accuracy: 0.9941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOT-A1wDfzDV",
        "colab_type": "text"
      },
      "source": [
        "*Na sledećem zajedničkom grafiku je prikazana funkcija gubitka na skupu za treniranje i validaciju, a potom i funkcija preciznosti.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt0mcagafzVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "64a6cb90-56d0-4180-9ba9-eafa484fec68"
      },
      "source": [
        "plot_loss_accuracy(100, alex_history_new)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv3HAcjqf7mX",
        "colab_type": "text"
      },
      "source": [
        "**TODO**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw5KbmOXf8Yu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "a610299e-feb7-40c2-9067-1c98fe485b6d"
      },
      "source": [
        "show_classification_report(alex_history_new, X_test, y_test)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-1896fb95dcd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_classification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malex_history_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-99-b35d74a96057>\u001b[0m in \u001b[0;36mshow_classification_report\u001b[0;34m(model, X_test, y_test)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_classification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'predict_classes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmcA8Q0hgA4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "58155826-fdc1-43b0-aaf3-f9547d4fb9dc"
      },
      "source": [
        "# Evaluate model\n",
        "score = alexnet_model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.030186228454113007\n",
            "Test accuracy: 0.991536021232605\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}